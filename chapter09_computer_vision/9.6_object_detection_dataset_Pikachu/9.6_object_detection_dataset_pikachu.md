# 9.6. 目标检测数据集（皮卡丘）

在目标检测领域并没有类似MNIST或Fashion-MNIST那样的小数据集。为了快速测试模型，我们合成了一个小的数据集。我们首先使用一个开源的皮卡丘3D模型生成了1,000张不同角度和大小的皮卡丘图像。然后我们收集了一系列背景图像，并在每张图的随机位置放置一张随机的皮卡丘图像。

![皮卡丘](https://github.com/monkeyDemon/Learn_Dive-into-DL-PyTorch/master/img/pikachu.png)

原书使用MXNet提供的工具将图像转换成二进制的RecordIO格式。该格式既可以降低数据集在磁盘上的存储开销，又能提高读取效率，这里我们不需要详细了解。

因此为了获得皮卡求数据集的原始文件，我们需要安装MXNet，装cpu版本即可，生成完数据集就可以卸载了

```
pip install mxnet
```

## 9.6.1. 获取数据集

首先引入必要的包
```
import sys
sys.path.append("../../")
import d2lzh_pytorch as d2l

import os
import json
import numpy as np
from PIL import Image
from matplotlib import pyplot as plt

import torch
import torchvision.transforms as transforms

pikachu_dataset = '../../dataset/pikachu'
```

RecordIO格式的皮卡丘数据集可以直接在网上下载。获取数据集的操作定义在download_pikachu函数中。

```python
def download_pikachu(data_dir):
    root_url = ('https://apache-mxnet.s3-accelerate.amazonaws.com/'
                'gluon/dataset/pikachu/')
    dataset = {'train.rec': 'e6bcb6ffba1ac04ff8a9b1115e650af56ee969c8',
               'train.idx': 'dcf7318b2602c06428b9988470c731621716c393',
               'val.rec': 'd6c33f799b4d058e82f2cb5bd9a976f69d72d520'}
    for k, v in dataset.items():
        d2l.download_url(root_url + k, data_dir)
```

与原书内容不同的是，这里我们为了后面使用Pytorch训练目标检测模型时更方便，需要将原书中提供的数据格式转换回我们更熟悉的png图片形式。

由于转换部分的代码与目标检测的学习关系并不大，具体的细节就省略了，感兴趣的同学详见`d2l.download_and_preprocess_pikachu_data`函数。

调用如下函数，一键完成皮卡丘数据集的准备工作，将数据处理成熟悉的png格式的图片和json格式的标注文件

```python
d2l.download_and_preprocess_pikachu_data(dir=pikachu_dataset)
```

## 9.6.2. 读取数据集

这里我们创建一个`PIKACHU`类（已经放入d2l中），用来加载前面生成的标注文件（包含了图片名称和对应的目标框信息的json）。然后我们即可创建一个pytorch的DataLoader来使用PIKACHU类完成训练过程的数据读取工作。

```python
# We created a class PIKACHU which loads the annotation file (json) 
# which contains image names along with their bounding box annotations. 
# 为方便后面使用，我们将PIKACHU封装到d2l中
class PIKACHU(torch.utils.data.Dataset):
    def __init__(self, data_dir, set, transform=None, target_transform=None):

        self.image_size = (3, 256, 256)
        self.images_dir = os.path.join(data_dir, set, 'images')

        self.set = set
        self.transform = transforms.Compose([
            transforms.ToTensor()])
        self.target_transform = target_transform

        annotations_file = os.path.join(data_dir, set, 'annotations.json')
        with open(annotations_file) as file:
            self.annotations = json.load(file)

    def __getitem__(self, index):

        annotations_i = self.annotations['data_' + str(index+1)]

        image_path = os.path.join(self.images_dir, annotations_i['image'])
        img = np.array(Image.open(image_path).convert('RGB').resize((self.image_size[2], self.image_size[1]), Image.BILINEAR))
        # print(img.shape)
        loc = np.array(annotations_i['loc'])

        loc_chw = np.zeros((4,))
        loc_chw[0] = (loc[0] + loc[2])/2
        loc_chw[1] = (loc[1] + loc[3])/2
        loc_chw[2] = (loc[2] - loc[0])  #width
        loc_chw[3] = (loc[3] - loc[1])  # height


        label = 1 - annotations_i['class']

        if self.transform is not None:
            img = self.transform(img)
        return (img, loc_chw, label)

    def __len__(self):
        return len(self.annotations)
```

下面我们读取一个小批量并打印图像和标签的形状。图像的形状和之前实验中的一样，依然是(批量大小, 通道数, 高, 宽)。而标签的形状则是(批量大小,  m , 4)，其中 m 等于数据集中单个图像最多含有的边界框个数。

小批量计算虽然高效，但它要求每张图像含有相同数量的边界框，以便放在同一个批量中。由于每张图像含有的边界框个数可能不同，我们为边界框个数小于 m 的图像填充非法边界框，直到每张图像均含有 m 个边界框。这样，我们就可以每次读取小批量的图像了。

图像中每个边界框的标签由长度为4的数组表示，4个元素分别表示边界框左上角的 x 和 y 轴坐标以及右下角的 x 和 y 轴坐标（值域在0到1之间）。

这里的皮卡丘数据集中每个图像均有且只有一个边界框，因此 m=1 。

```python
train_dataset = d2l.PIKACHU(pikachu_dataset, 'train')
val_dataset = d2l.PIKACHU(pikachu_dataset, 'val')

batch_size = 16
train_loader = torch.utils.data.DataLoader(train_dataset,
                                           batch_size=batch_size, shuffle=True,
                                           num_workers=4)
val_loader = torch.utils.data.DataLoader(val_dataset,
                                         batch_size=batch_size, shuffle=False,
                                         num_workers=4)
batch = next(iter(train_loader))
print(batch[0].shape, batch[1].shape, batch[2].shape)
```

输出结果：

```
torch.Size([16, 3, 256, 256]) torch.Size([16, 4]) torch.Size([16])
```

## 9.6.3. 图示数据

我们画出10张图像和它们中的边界框。

可以看到，皮卡丘的角度、大小和位置在每张图像中都不一样。当然，这是一个简单的人工数据集。实际中的数据通常会复杂得多。

```python
imgs = [train_dataset[i][0].permute(1,2,0) for i in range(10)]
labels = [d2l.center_2_hw(torch.Tensor(train_dataset[i][1]).unsqueeze(0)) for i in range(10)]

show_num_rows = 2
show_num_cols = 5
axes = d2l.show_images(imgs, show_num_rows, show_num_cols, scale=2)

for i in range(show_num_rows):
    for j in range(show_num_cols):
        index = i * show_num_cols + j
        ax = axes[i][j]
        label = labels[index]
        d2l.show_bboxes(ax, [label.squeeze(0)*256], colors=['r'])
plt.savefig('../../img/visual_pikachu_dataset.png')
```

![可视化皮卡求数据集](https://github.com/monkeyDemon/Learn_Dive-into-DL-PyTorch/master/img/visual_pikachu_dataset.png)

## 9.6.4. 小结

合成的皮卡丘数据集可用于测试目标检测模型。

目标检测的数据读取与图像分类的类似。然而，在引入边界框后，标签形状和图像增广（如随机裁剪）发生了变化。
